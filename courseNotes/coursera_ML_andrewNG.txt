Andrew NG coursera course


Lec 1.x: what is machine learning? 
- A computer program is said to LEARN from experience E wrt some task T and some performance measure P,
if its performance on T, as measured by P, improves with experience E.
e.g. Spam classification, regression
types - supervised, unsupervised, re-inforcement learning

Introduction to supervised learning: housing price prediction (regression), malignant vs benign tumor (classification) - labeled data
Introduction to unsupervised learning: working with unlabeled data,  e.g. clustering 
                              use case: google news, clustering same story/topic from different links,
                                        clustering individuals by extent og gene expression,
                                        organise computing clusters for efficient working,
                                        social network analysis: find cohesive groups
                                        market segmentation: group customers for efficient targeting,
                                       separating overlapping audio sources- 2 speakers at different distances from 2 microphones (SVD)


##############################################################  
Lec 2.x: Linear regression 

linear regression with one variable / univariate linear regression
                training data
                     |
                     v
                learning algo
                     |
                     v
size of house  -> hypothesis (h-theta(x)) -> estimated price
(test set x)                        (predicted Y)


1. Training set: x,y
2. total no. of training examples : m
3. Hypothesis function : h-theta(x) = theta0 + theta1 . x  => function of x for fixed values of theta(i)
4. parameters : theta(i) 
5. cost function : J(theta0, theta1)      => function of parameters theta(i)
6. gradient descent algo: used to minimise the cost function, to get optimal values of parameters theta(i).
7. alpha: Learning rate (controls the step size during gradient descent).
         If alpha is too small, convergence of algo is slow. 
         For large alpha, it can overshoot the minimum & also fail to converge (& may even diverge).
         As we approach the minima, the rate of change of slope (ie the magnitude of derivative) decreases (derivative=0 at the minima),
         so theta changes by smaller amounts in subsequent steps. Hence no need to reduce the value of alpha over time.


Choose theta(i) such that h-theta(x) is close to y for training examples (x,y) => minimize (1/2m) sum (h-i - y-i)^2 over theta(i).
definition of cost function/ squared error cost function (to be minimised wrt theta0 & theta1) : 
                J(theta0, theta1) = (1/2m) sum(i) (h-i - y-i)^2 
For a single theta, J(theta) is a parabolic function.
for multiple theta, J(theta) can be visualized as surface plots, or as contour plots (concentric ellipses).


gradient descent algo : used to minimise the cost function J(theta) 
           (gradient descent solves for theta(i) iteratively.
           In normal equations method, we can solve equations (with derivative=0 ?) for theta to get exact values. 
           However, gradient descent scales well (for hypothesis with many parameters) instead of the normal equations method.
           We choose starting value of parameter - the partial derivative is used to update the value of the parameter.
          
repeat until convergence {
  theta(j) := theta(j) - alpha. del/del_theta(j) J(theta0, theta1)  # [partial derivative with j = 0,1]
}
# update step - update simultaneously
temp0 := theta0 - alpha. del/del_theta0 J(theta0, theta1)
temp1 := theta1 - alpha. del/del_theta1 J(theta0, theta1)   # using previous value of theta0
theta0 := temp0
theta1 := temp1


The cost function for linear regression is always going to be convex function (bowl-shaped) with 1 global minimum only.

The above form of the algo is called Batch gradient descent: each step of gradient descent uses all training egs (parameter update
step involves sum over all m training egs).
There are other algos which use a subset of the training examples. 

use of linear algebra to handle training data with multiple features.


##########################################################################
Lec 3.x : linear algebra (addition, subtraction & multiplication with matrices & vectors; matrix inverse & transpose)

dim of matrix = no. of rows x no. of cols

matrix multiplication: [m x n] x [n x p] = [m x p]

h-theta(x) = theta0 + theta1 . x
in matrix notation, this can be written as: [prediction vector] = [data matrix] x [parameter matrix as vector]

properties:
1. matrix multiplication is not commutative:   A x B != B x A
2. matrix multiplication is associative :      A x (B x C) = (A x B) x C
3. identity matrix I : diagonal elements are 1, off-diagonals are 0
    A.I = I.A = A  -> these 2 I matrices have diferent dimensions
    A[m x n] . I[n x n] = I[m x m] . A[m x n] = A[m x n]
    
4. if A is an [m x m] square matrix, & if it has an inverse: A . A^-1 = A^-1 . A = I
   The matrix of all zeroes does not have an inverse.
   singular/ degenerate matrices - matrices which dont have inverse

5. matrix transpose: A = [m x n]
                     A^T = [n x m]


############################################################################
Lec 4.x: multivariate linear regression, feature scaling,
For features with different scales, the contours of theta space is skewed ovals, this will lead to longer time in the execution of 
the grad descent algo


###############   neural network   #################
Lec 8.1:
Classification problem with complex boundary (non linear hypothesis): one solution is to build logistic regression with the
raw features & product terms (non-linear features) of the raw features 
    ~ no. of features/parameters increases hugely as N increases.
    Also, the possibility of overfitting with such huge no of features (overfitting occurs for low data-to-parameter ratio).

For image classification problem, the no of features N is especially large (N = n x n, n is the no of pixels in the image).
Non-linear hypothesis is reqd 4 image classification.


Lec 8.2: one learning hypothesis


Lec 8.3:
Inputs: x(i) , x(0) = 1 <- bias unit
Output : h-theta(x) = 1/(1 + e^-thetaT.x)  - This form is the sigmoid/ logistic activation function.
Theta are the parameters or weights of the neural network

Input layer -> hidden layer -> output layer: h-theta(x)
Architecture of NN; shows how neurons in different layers are connected to each other.

Each node in the input layer contributes to all nodes a(i)(j) [ith node in hidden layer j] in the hidden layer.
a(i)(j) is the activation of unit i in layer j.
THETA(j) : The matrix of weights that controls the function mapping from layer j to j+1.

formula for activation term in layer 2 (the hidden layer):
a(1)(2) = g( theta(10)(1).x(0) + theta(11)(1).x(1) + theta(12)(1).x(2) + theta(13)(1). x(3) ) = g( z(1)(2) )

Similarly,
h-theta(x) = g( theta(10)(2).a(0)(2) + theta(11)(2).a(1)(2) + theta(12)(2).a(2)(2) + theta(13)(2). a(3)(2) ) 

Forward propagation: computation of activation function or g(z) = 1/(1 + e^ -z)  using inputs & weights at each layer.


Lec 8.4:
Neural network is equivalent to logistic regression on (new features computed using the activation function)
instead of (raw features x(i)).
The new features were obtained by applying activation function with weights on the raw features => the neural network gets to choose
its own features to feed into logistic regression.
NN uses hidden layer on input features to build more complex (non-linear) features.

Q. How to avoid overfitting with NN ?


Lec 8.5:
Non linear classification (non-linear decision boundary is required to separate positive & negative/ binary samples) example - XOR, XNOR.


Lec 8.6: another eg : hand-written digit classification


Lec 8.7: multiclass classification (pedestrian, car, bus, truck), representation of x(i) & y(i)


Lec 9.1: neural network (NN) cost function, similar form to that for logistic regression. 
Cost function measures how well the neural network fits training data.
J(theta) = -1/m sum [ y(i) log h-theta(x(i)) + ( 1 -y(i)) log ( 1 - h-theta(x(i)) )]  + lambda/2m . sum theta(j)^2
                                                                                                |
                                                                          regularization term, sum is from 1 to n (leave out bias term)


Lec 9.2:  back propagation (bp) algorithm to minimise cost function for NN.
we are back-propagating the errors from the output layer to the input layer.

      Step 1. Compute outputs (activation function & h-theta(x) ) using forward propagation.
      Step 2. use BP algo to compute derivatives. 
              delta(j)(L) = error of node j in layer L
              Compute the delta terms for each layer, starting from last layer. So, for last/ final layer (say, layer 4):
              d(j)(4) = a(j)(4) - y(j) 
                      = h-theta(x)(j) - y(j)   ; where h-theta(x)(j) is the jth output
      Step 3. To minimise the cost function, partial derivatives wrt the parameters are reqd. 
              It can be shown that the derivatives equal the product of activation function & delta term (computed in step 2),
              (ignoring the regularization term for the moment).
              This affects the intermediate weights such that the final output is optimised.


Lec 9.3: computation steps of backprop (BP intuition)


Lec 9.4: unrolling matrices to vectors (useful for optimisation)


Lec 9.5: gradient checking fix to ensure that Backprop is working correctly (?)
One-sided difference vs 2-sided difference formula for computing derivatives.


Lec 9.6: random initialisation.
Initialising all the theta values to zero (as done in logistic regression) does not work for neural network,
as parameters going into each of the hidden units in a layer would be equal.
Hence use random initialisation in [-€,€] to break this symmetry.


Lec 9.7: choice of architecture of the network.
# units in layer 1 =  dimension of input features
#units in last layer =  # output classes
No of hidden layers (default: 1) & no of hidden units in a layer (the more, the better).
Same no of hidden units in every hidden layer.
Training a NN:
  1. randomly initialise weights.
  2. Use forward propagation to compute h-theta(x).
  3. Compute cost function J-theta.
  4. Compute partial derivatives of cost function J-theta using backProp algo.
  5. Use gradient checking to check numerical estimates of derivatives of cost function with the values from backProp.
     Then disable gradient checking.
  6. Use gradient descent or advanced optimisation with backProp to minimise J-theta as a function of parameters theta.
     For NN, J-theta is non-convex & is theoretically susceptible to getting stuck in local minima.
     In practice, it is not usually a huge problem.


Lec 9.8: using NN for autonomous driving.
Input: road image
Output: steering direction with a confidence value.

